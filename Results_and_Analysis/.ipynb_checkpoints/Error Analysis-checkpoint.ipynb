{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "from IPython.display import display, Audio\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_audio(clip,sr):\n",
    "    display(Audio(clip,rate=sr))\n",
    "    \n",
    "def get_transcript_paths(audio_paths):\n",
    "    transcript_paths = [] \n",
    "    for audio_path in audio_paths:\n",
    "        rest = audio_path.strip('../data/')\n",
    "        i = rest.find('/')\n",
    "        folder_num = rest[:i]\n",
    "        start_at = len('../data/' + folder_num +'/audio/')\n",
    "        index = audio_path.find('/',start_at)\n",
    "        id = audio_path[start_at:index]\n",
    "        transcript_paths.append('../data/'+folder_num+'/conversations/'+id+'.json')\n",
    "    return transcript_paths\n",
    "\n",
    "def get_failure_stats(clip_encodings):\n",
    "    cl_cl_errors = []\n",
    "    cl_ag_errors = []\n",
    "    for clip_encoding in clip_encodings:\n",
    "        clip_info = clip_encoding.split('_')\n",
    "        audio_path = clip_info[0]\n",
    "        seg_index = int(clip_info[1])\n",
    "        window_start = int(clip_info[2]) - WINDOW_SIZE\n",
    "        transcript_path = get_transcript_paths([audio_path])[0]\n",
    "    \n",
    "        with open(transcript_path,'r') as conv_json:\n",
    "            transcript = json.loads(conv_json.read())\n",
    "            if(transcript['segments'][seg_index+1]['caller_role'] == 'AG'):\n",
    "                cl_ag_errors.append(clip_encoding)\n",
    "            else:\n",
    "                cl_cl_errors.append(clip_encoding)\n",
    "    return cl_cl_errors,cl_ag_errors\n",
    "    \n",
    "def get_clip_info(clip_encoding):\n",
    "    clip_info = clip_encoding.split('_')\n",
    "    audio_path = clip_info[0]\n",
    "    seg_index = int(clip_info[1])\n",
    "    window_start = int(clip_info[2]) - WINDOW_SIZE\n",
    "    \n",
    "    transcript_path = get_transcript_paths([audio_path])[0]\n",
    "    \n",
    "    with open(transcript_path,'r') as conv_json, open(audio_path,'rb') as conv_audio:\n",
    "        audio, sr = lr.load(conv_audio,sr=8000, mono=False)\n",
    "        transcript = json.loads(conv_json.read())\n",
    "        \n",
    "        start_ms = transcript['segments'][seg_index]['start_ms'] + window_start\n",
    "        end_ms = start_ms+WINDOW_SIZE\n",
    "        start_sample_window = lr.core.time_to_samples(start_ms/1000, sr=8000) #sr is 8000\n",
    "        end_sample_window = lr.core.time_to_samples(end_ms/1000, sr=8000)      #sr is 8000  \n",
    "        clip_audio = audio[:,start_sample_window:end_sample_window] #notice we grab both channels\n",
    "        \n",
    "        start_ms = transcript['segments'][seg_index]['start_ms']\n",
    "        end_ms = start_ms+transcript['segments'][seg_index]['duration_ms']\n",
    "        start_sample = lr.core.time_to_samples(start_ms/1000, sr=8000) #sr is 8000\n",
    "        end_sample = lr.core.time_to_samples(end_ms/1000, sr=8000)      #sr is 8000\n",
    "        seg_audio = audio[:,start_sample:end_sample]\n",
    "        \n",
    "        start_ms = transcript['segments'][seg_index+1]['start_ms']\n",
    "        end_ms = start_ms+transcript['segments'][seg_index+1]['duration_ms']\n",
    "        start_sample = lr.core.time_to_samples(start_ms/1000, sr=8000) #sr is 8000\n",
    "        end_sample = lr.core.time_to_samples(end_ms/1000, sr=8000)      #sr is 8000\n",
    "        seg_audio_next = audio[:,start_sample:end_sample]\n",
    "        \n",
    "        print(\"================\")\n",
    "        print('Entire segment:')\n",
    "        play_audio(seg_audio,8000)\n",
    "        print(\"Transcript: \",transcript['segments'][seg_index]['transcript'])\n",
    "        print('Next segment:')\n",
    "        play_audio(seg_audio_next,8000)\n",
    "        print(\"Transcript: \",transcript['segments'][seg_index+1]['transcript'])\n",
    "        print('Window used for classification:')\n",
    "        play_audio(clip_audio,8000)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos_clips_dl = np.load('../util/false_positives_dl_'+str(WINDOW_SIZE)+'.npy')\n",
    "cl_cl_dl, cl_ag_dl = get_failure_stats(false_pos_clips_dl)\n",
    "\n",
    "\n",
    "false_pos_clips_rf = np.load('../util/false_positives_rf_'+str(WINDOW_SIZE)+'.npy')\n",
    "cl_cl_rf, cl_ag_rf = get_failure_stats(false_pos_clips_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_neg_clips_dl = np.load('../util/false_negatives_dl_'+str(WINDOW_SIZE)+'.npy')\n",
    "cl_fn_dl, ag_fn_dl = get_failure_stats(false_neg_clips_dl)\n",
    "\n",
    "false_neg_clips_rf = np.load('../util/false_negatives_rf_'+str(WINDOW_SIZE)+'.npy')\n",
    "cl_fn_rf, ag_fn_rf = get_failure_stats(false_neg_clips_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FALSE NEGATIVE STATS\n",
    "n_fn_ag_dl = len(ag_fn_dl)\n",
    "print('DL number of false negatives:', n_fn_ag_dl)\n",
    "\n",
    "\n",
    "n_fn_ag_rf = len(ag_fn_rf)\n",
    "print('RF number of false negatives:', n_fn_ag_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.choice(cl_fn_dl,5,replace=False)\n",
    "for clip_encoding in sample:\n",
    "    get_clip_info(clip_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##FALSE POSITIVE STATS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cl_dl = len(cl_cl_dl)\n",
    "n_ag_dl = len(cl_ag_dl)\n",
    "print('DL: Pause mistakes:',n_cl_dl)\n",
    "print('DL: Too early mistakes',n_ag_dl)\n",
    "print('DL: Total',n_ag_dl+n_cl_dl)\n",
    "print('DL Pause Failure Rate:',n_cl_dl/(n_cl_dl + n_ag_dl))\n",
    "\n",
    "n_cl_rf = len(cl_cl_rf)\n",
    "n_ag_rf = len(cl_ag_rf)\n",
    "print('RF: Pause mistakes:',n_cl_rf)\n",
    "print('RF: Too early mistakes',n_ag_rf)\n",
    "print('RF: Total',n_ag_rf+n_cl_rf)\n",
    "print('RF: Pause Failure Rate:',n_cl_rf/(n_cl_rf + n_ag_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clip_encoding in cl_ag_dl:\n",
    "    get_clip_info(clip_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos_sample = np.random.choice(false_pos_clips,100,replace=False)\n",
    "false_neg_sample = np.random.choice(false_neg_clips,100,replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clip_encoding in false_pos_sample:\n",
    "    get_clip_info(clip_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clip_encoding in false_neg_sample:\n",
    "    get_clip_info(clip_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
