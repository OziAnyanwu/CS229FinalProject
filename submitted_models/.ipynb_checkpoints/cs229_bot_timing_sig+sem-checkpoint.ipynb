{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 1 DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET THE DATA FIRST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import random\n",
    "import os\n",
    "from IPython.display import display, Audio\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../util/tokenizer.txt','r') as infile:\n",
    "    data = json.load(infile)\n",
    "    tokenizer = tf.keras.preprocessing.text.tokenizer_from_json(data)\n",
    "VOCAB_SIZE = len(tokenizer.word_index)\n",
    "TEXT_PADDING = 8\n",
    "WINDOW_SIZE = 1000 #in ms\n",
    "SLIDE_STRIDE = 300 # in ms\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 64\n",
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACT INPUTS AND TARGETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mfccs = np.load('../util/X_mfccs_error_4000.npy')\n",
    "X_transcripts = np.load('../util/X_transcripts_error_4000.npy')\n",
    "clips = np.load('../util/X_clips_error_4000.npy')\n",
    "Y = np.load('../util/labels_error_4000.npy')\n",
    "print(X_mfccs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOAD TRAIN AND TEST SPLITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mfcc, X_test_mfcc, X_train_transcript, X_test_transcript, clips_train, clips_test, y_train, y_test = train_test_split(X_mfccs,X_transcripts,clips,Y,test_size=0.1)\n",
    "print(X_train_mfcc.shape)\n",
    "print(X_train_transcript.shape)\n",
    "print(clips_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.mean(X_train_mfcc,axis=0)\n",
    "std_dev = np.std(X_train_mfcc,axis=0)\n",
    "X_train_mfcc -= mu\n",
    "X_test_mfcc -= mu\n",
    "X_train_mfcc /= std_dev\n",
    "X_test_mfcc /= std_dev\n",
    "print(X_train_mfcc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mfcc = X_train_mfcc[...,np.newaxis]\n",
    "X_test_mfcc = X_test_mfcc[...,np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mfcc[0].shape\n",
    "X_train_mfcc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STAGE 2 BUILDING AND COMPILING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BUILD THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_mfcc = tf.keras.Sequential()\n",
    "\n",
    "#conv layer 1\n",
    "mfcc_input = tf.keras.layers.Input(shape=X_train_mfcc[0].shape, name='mfcc_input')\n",
    "conv1 = tf.keras.layers.Conv2D(128,(3,3),\n",
    "                                 activation='relu',\n",
    "                                 input_shape=X_train_mfcc[0].shape,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001))(mfcc_input)\n",
    "norm1 = tf.keras.layers.BatchNormalization()(conv1)\n",
    "pool1 = tf.keras.layers.MaxPool2D((3,3),strides=(2,2),padding='same')(norm1)\n",
    "\n",
    "#conv layer 2\n",
    "conv2 = tf.keras.layers.Conv2D(64,(3,3),\n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001))(pool1)\n",
    "norm2 = tf.keras.layers.BatchNormalization()(conv2)\n",
    "pool2 = tf.keras.layers.MaxPool2D((3,3),strides=(2,2),padding='same')(norm2)\n",
    "\n",
    "\n",
    "#conv layer 3\n",
    "conv3 = tf.keras.layers.Conv2D(32,(2,2),\n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001))(pool2)\n",
    "norm3 = tf.keras.layers.BatchNormalization()(conv3)\n",
    "pool3 = tf.keras.layers.MaxPool2D((2,2),strides=(2,2),padding='same')(norm3)\n",
    "\n",
    "\n",
    "\n",
    "# #flatten output\n",
    "flat = tf.keras.layers.Flatten()(pool3)\n",
    "dense1 = tf.keras.layers.Dense(64,activation = 'relu')(flat)\n",
    "drop1 = tf.keras.layers.Dropout(0.25)(dense1)\n",
    "\n",
    "dense2 = tf.keras.layers.Dense(64,activation = 'relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(0.25)(dense2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_trans = tf.keras.Sequential()\n",
    "trans_input = tf.keras.layers.Input(shape=X_train_transcript[0].shape, name='trans_input')\n",
    "emb = tf.keras.layers.Embedding(VOCAB_SIZE, 128, input_length=TEXT_PADDING)(trans_input)\n",
    "\n",
    "#LMST Layer 1\n",
    "lstm1 = tf.keras.layers.LSTM(128,activation='relu',return_sequences = True)(emb)\n",
    "lstm_drop_1 = tf.keras.layers.Dropout(0.25)(lstm1)\n",
    "\n",
    "#LMST Layer 2\n",
    "lstm2 = tf.keras.layers.LSTM(128,activation='relu')(lstm_drop_1)\n",
    "lstm_drop_2 = tf.keras.layers.Dropout(0.25)(lstm2)\n",
    "\n",
    "#Dense \n",
    "lstm_dense_1 = tf.keras.layers.Dense(64,activation='relu')(lstm_drop_2)\n",
    "lstm_drop_3 = tf.keras.layers.Dropout(0.25)(lstm_dense_1)\n",
    "\n",
    "#Dense \n",
    "lstm_dense_2 = tf.keras.layers.Dense(64,activation='relu')(lstm_drop_3)\n",
    "lstm_drop_4 = tf.keras.layers.Dropout(0.25)(lstm_dense_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output layer\n",
    "concat = tf.keras.layers.concatenate([drop2,lstm_drop_4])\n",
    "output = tf.keras.layers.Dense(1,activation='sigmoid')(concat)\n",
    "# print(concat.shape)\n",
    "# model.add()\n",
    "# model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
    "model = tf.keras.Model(inputs=[mfcc_input,trans_input],outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(loss='binary_crossentropy',optimizer=op, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit([X_train_mfcc,X_train_transcript],y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = result.history\n",
    "tr_acc = history['accuracy']\n",
    "val_acc = history['val_accuracy']\n",
    "epochs = range(1, len(tr_acc)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,9))\n",
    "plt.plot(epochs,tr_acc,'bo',label='Training acc')\n",
    "plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "plt.title('Training and Val Accuracy for Signals + Semantics')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim((0.6,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INFERENCE:\n",
    "X_test_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate([X_test_mfcc,X_test_transcript],y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ERROR ANALYSIS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict([X_test_mfcc,X_test_transcript])\n",
    "valid_indexes = []\n",
    "invalid_indexes=[]\n",
    "for i in range(len(y_test)):\n",
    "    if(y_test[i] == 0):\n",
    "        invalid_indexes.append(i)\n",
    "    else:\n",
    "        valid_indexes.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_pred(val):\n",
    "    return np.around(val)\n",
    "print(\"PERFORMANCE ON POSITIVE EXAMPLES:\")\n",
    "total_pos = len(valid_indexes)\n",
    "total_right_pops = 0\n",
    "false_neg_clips = []\n",
    "for i in valid_indexes:\n",
    "    if(get_pred(predictions[i]) == get_pred(y_test[i])):\n",
    "        total_right_pops += 1\n",
    "    else:\n",
    "        print(clips_test[i])\n",
    "        false_neg_clips.append(clips_test[i])\n",
    "        print(\"Prediction: \",get_pred(predictions[i]),\". Label: \", get_pred(y_test[i]))\n",
    "    \n",
    "print(\"TOTAL POSITIVE EXMPLES: \", total_pos)\n",
    "print(\"TOTAL CORRECT POSITIVE:\", total_right_pops)\n",
    "print(\"POSITIVE EXAMPLES ACC: \", total_right_pops/total_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PERFORMANCE ON NEGATIVE EXAMPLES:\")\n",
    "total_neg = len(invalid_indexes)\n",
    "total_right_neg = 0\n",
    "false_pos_clips = []\n",
    "for i in invalid_indexes:\n",
    "    if(get_pred(predictions[i]) == get_pred(y_test[i])):\n",
    "        total_right_neg += 1\n",
    "    else:\n",
    "        print(clips_test[i])\n",
    "        false_pos_clips.append(clips_test[i])\n",
    "        print(\"Prediction: \", get_pred(predictions[i]),\". Label: \",get_pred(y_test[i]))\n",
    "print(\"TOTAL NEGATIVE EXMPLES: \", total_neg)\n",
    "print(\"TOTAL CORRECT NEGATIVE:\", total_right_neg)\n",
    "print(\"NEGATIVE EXAMPLES ACC: \", total_right_neg/total_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TOTAL EXMPLES: \", total_neg + total_pos)\n",
    "print(\"TOTAL CORRECT :\", total_right_neg + total_right_pops)\n",
    "print(\"ACC: \", (total_right_neg + total_right_pops)/(total_neg + total_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "false_pos_clips = np.array(false_pos_clips)\n",
    "false_neg_clips = np.array(false_neg_clips)\n",
    "np.save('../util/false_positives_4000.npy',false_pos_clips)\n",
    "np.save('../util/false_negatives_4000.npy',false_neg_clips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLD MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "#conv layer 1\n",
    "model.add(tf.keras.layers.Conv2D(64,(3,3),\n",
    "                                 activation='relu',\n",
    "                                 input_shape=X_train[0].shape,\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D((3,3),strides=(2,2),padding='same'))\n",
    "\n",
    "#conv layer 2\n",
    "model.add(tf.keras.layers.Conv2D(32,(3,3),\n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D((3,3),strides=(2,2),padding='same'))\n",
    "\n",
    "#conv layer 3\n",
    "model.add(tf.keras.layers.Conv2D(32,(2,2),\n",
    "                                 activation='relu',\n",
    "                                 kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPool2D((2,2),strides=(2,2),padding='same'))\n",
    "\n",
    "#flatten output\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64,activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#flatten output\n",
    "model.add(tf.keras.layers.Dense(64,activation = 'relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "\n",
    "#output layer\n",
    "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "op = tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(loss='binary_crossentropy',optimizer=op, metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train, epochs = EPOCHS, batch_size = BATCH_SIZE,validation_split = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
